{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 16:52:29.050066: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-27 16:52:29.054251: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 16:52:29.145167: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-27 16:52:29.147027: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-27 16:52:29.705160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.applications import Xception\n",
    "from keras.applications.xception import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Récupérer les listes images et texte dans un fichier texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les listes ont été écrites dans le fichier label_txt_img_info.txt.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#df = pd.read_csv('/mnt/c/Users/steph/OneDrive/Images/Rakuten/df_cleaned.csv')\n",
    "df = pd.read_csv('/mnt/c/Users/steph/OneDrive/Images/Rakuten/X_train_bis.csv')\n",
    "\n",
    "# Création d'un dictionnaire pour stocker les listes d'image_name, designation et description par label\n",
    "label_image_info = {}\n",
    "\n",
    "# Grouper les données par le label (prdtypecode)\n",
    "grouped = df.groupby('prdtypecode')\n",
    "\n",
    "# Parcourir chaque groupe et collecter les 'image_name', designation et description\n",
    "for label, group in grouped:\n",
    "    image_info = {\n",
    "        'image_name': group['image_name'].tolist(),\n",
    "        'designation': group['designation'].tolist(),\n",
    "        'description': group['description'].tolist()\n",
    "    }\n",
    "    label_image_info[label] = image_info\n",
    "\n",
    "# Écrire les listes dans un fichier texte\n",
    "with open('label_txt_img_info.txt', 'w', encoding='utf-8') as file:\n",
    "    for label, image_info in label_image_info.items():\n",
    "        file.write(f\"Label {label}:\\n\")\n",
    "        for i in range(len(image_info['image_name'])):\n",
    "            file.write(f\"Image Name: {image_info['image_name'][i]}\\n\")\n",
    "            file.write(f\"Designation: {image_info['designation'][i]}\\n\")\n",
    "            file.write(f\"Description: {image_info['description'][i]}\\n\\n\")\n",
    "\n",
    "print(\"Les listes ont été écrites dans le fichier label_txt_img_info.txt.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('french') + stopwords.words('english') + stopwords.words('german') +[ \\\n",
    "                'plus', 'peut', 'tout', 'etre', 'sans', 'dont', 'aussi',  \\\n",
    "                  'comme', 'meme', 'bien','leurs', 'elles', 'cette','celui',   \\\n",
    "                  'ainsi', 'encore', 'alors', 'toujours', 'toute','deux', 'nouveau',   \\\n",
    "                  'peu', 'car', 'autre', 'jusqu', 'quand', 'ici', 'ceux', 'enfin',  \\\n",
    "                  'jamais', 'autant', 'tant', 'avoir', 'moin', 'celle', 'tous',   \\\n",
    "                  'contre', 'pourtant', 'quelque', 'toutes', 'surtout', 'cet',  \\\n",
    "                  'comment', 'rien', 'avant', 'doit', 'autre', 'depuis', 'moins',  \\\n",
    "                  'tre', 'souvent', 'etait', 'pouvoir', 'apre', 'non', 'ver', 'quel',   \\\n",
    "                  'pourquoi', 'certain', 'fait', 'faire', 'sou', 'donc', 'trop',  \\\n",
    "                  'quelques', 'parfois', 'tres', 'donc', 'dire', 'eacute', 'egrave',  \\\n",
    "                  'rsquo', 'agrave', 'ecirc', 'nbsp', 'acirc', 'apres', 'autres',  \\\n",
    "                  'ocirc', 'entre', 'sous', 'quelle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateTextANDcleaning(data):\n",
    "    df = data\n",
    "    #valeurs MANQUANTES\n",
    "    df['designation'] = df['designation'].astype('string')\n",
    "    df['description'] = df['description'].astype('string')\n",
    "\n",
    "    # remplacement des Nan par une chaîne de caractère\n",
    "    df['description'].fillna('', inplace=True)\n",
    "\n",
    "    #create text\n",
    "    df['text']=\"\"\n",
    "    for i in range(df.shape[0]):\n",
    "        df['text'][i] = create_text(df['designation'][i], df['description'][i])\n",
    "\n",
    "    df['text'] = df['text'].str.split()\n",
    "\n",
    "    df['text'] = df['text'].apply(lambda x: unique_description(x))\n",
    "    df['text'] = df['text'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    df['text'] = df['text'].apply(lambda text : lower_case(text))\n",
    "    df['text'] = df['text'].apply(lambda text : remove_accent(text))\n",
    "\n",
    "    df['text'] = df['text'].apply(lambda text : remove_htmltags(text))\n",
    "    df['text'] = df['text'].apply(lambda text : keeping_essentiel(text))\n",
    "\n",
    "    # Initialiser la variable des mots vides\n",
    "    df['text'] = df['text'].str.split()\n",
    "    df['text']= df['text'].apply(lambda x: operation(x))\n",
    "\n",
    "    df['text'] = df['text'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "    return df['text']\n",
    "\n",
    "\n",
    "def create_text(text1, text2):\n",
    "    if pd.isna(text2):\n",
    "        text = text1\n",
    "    else:\n",
    "        text = text1 +\" \"+ text2\n",
    "    return text\n",
    "\n",
    "def unique_description(text):\n",
    "    unique=[text[0]]\n",
    "    for mot in text:\n",
    "        if mot not in unique:\n",
    "            unique.append(mot)\n",
    "    return unique\n",
    "\n",
    "def lower_case(text):\n",
    "    text = text.lower().strip()\n",
    "    return text\n",
    "\n",
    "def remove_accent(string):\n",
    "    string = string.replace('á', 'a')\n",
    "    string = string.replace('â', 'a')\n",
    "\n",
    "    string = string.replace('é', 'e')\n",
    "    string = string.replace('è', 'e')\n",
    "    string = string.replace('ê', 'e')\n",
    "    string = string.replace('ë', 'e')\n",
    "\n",
    "    string = string.replace('î', 'i')\n",
    "    string = string.replace('ï', 'i')\n",
    "\n",
    "    string = string.replace('ö', 'o')\n",
    "    string = string.replace('ô', 'o')\n",
    "    string = string.replace('ò', 'o')\n",
    "    string = string.replace('ó', 'o')\n",
    "\n",
    "    string = string.replace('ù', 'u')\n",
    "    string = string.replace('û', 'u')\n",
    "    string = string.replace('ü', 'u')\n",
    "\n",
    "    string = string.replace('ç', 'c')\n",
    "\n",
    "    return string\n",
    "\n",
    "def remove_htmltags(text):\n",
    "    text = re.sub('<[^<]+?>', '',text)\n",
    "    return text\n",
    "\n",
    "def keeping_essentiel(text):\n",
    "    text = re.sub(r\"[^a-zA-Z]+\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def operation(x):\n",
    "    my_list=[]\n",
    "    for mot in x:\n",
    "        if (mot not in stop_words and len(mot)>2):\n",
    "            my_list.append(mot)\n",
    "    return my_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>designation</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Un Cyclone A La Jamaique.</td>\n",
       "      <td>Traduit de l'anglais par JEAN TALVA.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 designation                           description\n",
       "0  Un Cyclone A La Jamaique.  Traduit de l'anglais par JEAN TALVA."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "designation1 = \"Un Cyclone A La Jamaique.\"\n",
    "description1 = \"Traduit de l'anglais par JEAN TALVA.\"\n",
    "\n",
    "\n",
    "df = {'designation': [designation1],\n",
    "        'description': [description1]}\n",
    "\n",
    "# création d'un dataframe\n",
    "df_text = pd.DataFrame(df)\n",
    "df_text = df_text.astype(str)\n",
    "\n",
    "df_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 designation                           description  \\\n",
      "0  Un Cyclone A La Jamaique.  Traduit de l'anglais par JEAN TALVA.   \n",
      "\n",
      "                                          text  \n",
      "0  cyclone jamaique traduit anglais jean talva  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_213794/1898794411.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][i] = create_text(df['designation'][i], df['description'][i])\n"
     ]
    }
   ],
   "source": [
    "# Nettoyage du texte avec la fonction CreateTextANDcleaning\n",
    "CreateTextANDcleaning(df_text)\n",
    "\n",
    "print(df_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = df_text['text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    cyclone jamaique traduit anglais jean talva\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400 \n",
    "text = tokenizer.texts_to_sequences(prompt)\n",
    "\n",
    "text = keras.preprocessing.sequence.pad_sequences(text,\n",
    "                                                  maxlen = maxlen,\n",
    "                                                  padding='post')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3 4 5 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-27 16:52:31.205576: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-09-27 16:52:31.340404: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "#model_conv1D = load_model('/mnt/c/Users/steph/OneDrive/Images/Rakuten/save_data/model.h5/DL_RNN_Conv1D/model.h5_Conv1D_08092023.h5')\n",
    "\n",
    "model_conv1D = load_model('/mnt/c/Users/steph/OneDrive/Images/Rakuten/save_data_bis/model_github_save/conv1d_model.h5')\n",
    "#model_conv1D = load_model('/mnt/c/Users/steph/OneDrive/Images/Rakuten/save_data_bis/Text/weights_model_2309/model_rnn1.h5')\n",
    "\n",
    "#weights_conv1D = load_weights('weights_conv1d.h5')\n",
    "#model_conv1D = load_model('model_conv1d.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 65ms/step\n"
     ]
    }
   ],
   "source": [
    "# prédiction conv1D sur le texte tokenizé \n",
    "y_pred_text = model_conv1D.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.0158703e-03, 1.2708700e-02, 5.4030879e-03, 3.5592949e-04,\n",
       "        1.9397237e-03, 1.1224814e-03, 1.8702996e-03, 3.3140709e-03,\n",
       "        6.1604154e-04, 5.4257684e-03, 1.9925074e-03, 1.0485913e-01,\n",
       "        6.2565743e-03, 4.7089392e-03, 1.0588962e-02, 2.8872348e-02,\n",
       "        4.8137497e-02, 1.5715798e-02, 3.2164801e-03, 4.2344056e-04,\n",
       "        6.2436488e-04, 7.5107366e-03, 5.2588056e-03, 6.4597678e-01,\n",
       "        7.1760580e-02, 2.3161517e-03, 8.8409261e-06]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe prédite en utilisant argmax\n",
    "y_pred_class = np.argmax(y_pred_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.01587009e-01 1.27086997e+00 5.40308774e-01 3.55929472e-02\n",
      "  1.93972379e-01 1.12248145e-01 1.87029958e-01 3.31407100e-01\n",
      "  6.16041534e-02 5.42576849e-01 1.99250743e-01 1.04859133e+01\n",
      "  6.25657439e-01 4.70893919e-01 1.05889618e+00 2.88723493e+00\n",
      "  4.81374979e+00 1.57157981e+00 3.21648002e-01 4.23440561e-02\n",
      "  6.24364875e-02 7.51073658e-01 5.25880575e-01 6.45976791e+01\n",
      "  7.17605782e+00 2.31615171e-01 8.84092588e-04]]\n"
     ]
    }
   ],
   "source": [
    "prob_class_text = y_pred_text * 100\n",
    "\n",
    "print(prob_class_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/mnt/c/Users/steph/OneDrive/Images/Rakuten/images/image_train/image_975548119_product_225089670.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_xception = load_weights('weights_xception.h5')\n",
    "model_xception = load_model('/mnt/c/Users/steph/OneDrive/Images/Rakuten/save_data_bis/model_github_save/checkpoint_Xception_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(image_path, target_size=(299, 299))  # Xception : taille d'image de 299x299\n",
    "img = image.img_to_array(img)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "img = preprocess_input(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 369ms/step\n"
     ]
    }
   ],
   "source": [
    "# prédiction avec modèle xception sur les images \n",
    "y_pred_image = model_xception.predict(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.69720376e-01, 1.63446832e-02, 7.89960450e-06, 2.50825597e-05,\n",
       "        1.01187848e-04, 3.55430529e-05, 3.00065294e-04, 2.63054215e-04,\n",
       "        9.90819535e-05, 6.01580650e-05, 4.20229360e-02, 1.00397326e-01,\n",
       "        2.17743254e-05, 5.27036435e-04, 2.93634279e-04, 9.56937147e-05,\n",
       "        1.51205404e-05, 1.52210059e-05, 2.79477108e-02, 1.06002763e-03,\n",
       "        4.87955513e-05, 2.92930286e-04, 3.01220780e-03, 3.30895069e-03,\n",
       "        8.84286070e-04, 3.30458358e-02, 5.33855491e-05]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.6972038e+01 1.6344683e+00 7.8996044e-04 2.5082559e-03 1.0118784e-02\n",
      "  3.5543053e-03 3.0006530e-02 2.6305422e-02 9.9081956e-03 6.0158065e-03\n",
      "  4.2022934e+00 1.0039733e+01 2.1774326e-03 5.2703645e-02 2.9363427e-02\n",
      "  9.5693711e-03 1.5120540e-03 1.5221006e-03 2.7947712e+00 1.0600276e-01\n",
      "  4.8795552e-03 2.9293029e-02 3.0122077e-01 3.3089507e-01 8.8428609e-02\n",
      "  3.3045835e+00 5.3385547e-03]]\n"
     ]
    }
   ],
   "source": [
    "prob_class_img = y_pred_image * 100\n",
    "\n",
    "print(prob_class_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_produit</th>\n",
       "      <th>labels</th>\n",
       "      <th>prob_class_text</th>\n",
       "      <th>prob_class_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Livres adultes</td>\n",
       "      <td>0.901587</td>\n",
       "      <td>76.972038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Jeux Vidéos</td>\n",
       "      <td>1.270870</td>\n",
       "      <td>1.634468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>Accessoires de Jeux Vidéos</td>\n",
       "      <td>0.540309</td>\n",
       "      <td>0.000790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>Consoles de jeux</td>\n",
       "      <td>0.035593</td>\n",
       "      <td>0.002508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1140</td>\n",
       "      <td>Figurine</td>\n",
       "      <td>0.193972</td>\n",
       "      <td>0.010119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1160</td>\n",
       "      <td>Carte à Collectionner</td>\n",
       "      <td>0.112248</td>\n",
       "      <td>0.003554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1180</td>\n",
       "      <td>Masques</td>\n",
       "      <td>0.187030</td>\n",
       "      <td>0.030007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1280</td>\n",
       "      <td>Jouets pour Enfants</td>\n",
       "      <td>0.331407</td>\n",
       "      <td>0.026305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1281</td>\n",
       "      <td>Jeux de Cartes et de société</td>\n",
       "      <td>0.061604</td>\n",
       "      <td>0.009908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1300</td>\n",
       "      <td>Produits télécommandés</td>\n",
       "      <td>0.542577</td>\n",
       "      <td>0.006016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1301</td>\n",
       "      <td>Vêtements pour enfants</td>\n",
       "      <td>0.199251</td>\n",
       "      <td>4.202293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1302</td>\n",
       "      <td>Jouets pour Enfants</td>\n",
       "      <td>10.485913</td>\n",
       "      <td>10.039733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1320</td>\n",
       "      <td>Produits Bébés et Enfants</td>\n",
       "      <td>0.625657</td>\n",
       "      <td>0.002177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1560</td>\n",
       "      <td>Literies et Meubles</td>\n",
       "      <td>0.470894</td>\n",
       "      <td>0.052704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1920</td>\n",
       "      <td>Accessoires Maison</td>\n",
       "      <td>1.058896</td>\n",
       "      <td>0.029363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1940</td>\n",
       "      <td>Alimentation</td>\n",
       "      <td>2.887235</td>\n",
       "      <td>0.009569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2060</td>\n",
       "      <td>Décoration d'intérieur</td>\n",
       "      <td>4.813750</td>\n",
       "      <td>0.001512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2220</td>\n",
       "      <td>Accessoires Animaux</td>\n",
       "      <td>1.571580</td>\n",
       "      <td>0.001522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2280</td>\n",
       "      <td>Journaux et Magazines</td>\n",
       "      <td>0.321648</td>\n",
       "      <td>2.794771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2403</td>\n",
       "      <td>Livres et Revues</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.106003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2462</td>\n",
       "      <td>Jeux</td>\n",
       "      <td>0.062436</td>\n",
       "      <td>0.004880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2522</td>\n",
       "      <td>Papeterie</td>\n",
       "      <td>0.751074</td>\n",
       "      <td>0.029293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2582</td>\n",
       "      <td>Mobilier</td>\n",
       "      <td>0.525881</td>\n",
       "      <td>0.301221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2583</td>\n",
       "      <td>Piscine</td>\n",
       "      <td>64.597679</td>\n",
       "      <td>0.330895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2585</td>\n",
       "      <td>Jardinage</td>\n",
       "      <td>7.176058</td>\n",
       "      <td>0.088429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2705</td>\n",
       "      <td>Livres</td>\n",
       "      <td>0.231615</td>\n",
       "      <td>3.304584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2905</td>\n",
       "      <td>Jeux en ligne et Logiciels</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    code_produit                        labels  prob_class_text  \\\n",
       "0             10                Livres adultes         0.901587   \n",
       "1             40                   Jeux Vidéos         1.270870   \n",
       "2             50    Accessoires de Jeux Vidéos         0.540309   \n",
       "3             60              Consoles de jeux         0.035593   \n",
       "4           1140                      Figurine         0.193972   \n",
       "5           1160         Carte à Collectionner         0.112248   \n",
       "6           1180                       Masques         0.187030   \n",
       "7           1280           Jouets pour Enfants         0.331407   \n",
       "8           1281  Jeux de Cartes et de société         0.061604   \n",
       "9           1300        Produits télécommandés         0.542577   \n",
       "10          1301        Vêtements pour enfants         0.199251   \n",
       "11          1302           Jouets pour Enfants        10.485913   \n",
       "12          1320     Produits Bébés et Enfants         0.625657   \n",
       "13          1560           Literies et Meubles         0.470894   \n",
       "14          1920            Accessoires Maison         1.058896   \n",
       "15          1940                  Alimentation         2.887235   \n",
       "16          2060        Décoration d'intérieur         4.813750   \n",
       "17          2220           Accessoires Animaux         1.571580   \n",
       "18          2280         Journaux et Magazines         0.321648   \n",
       "19          2403              Livres et Revues         0.042344   \n",
       "20          2462                          Jeux         0.062436   \n",
       "21          2522                     Papeterie         0.751074   \n",
       "22          2582                      Mobilier         0.525881   \n",
       "23          2583                       Piscine        64.597679   \n",
       "24          2585                     Jardinage         7.176058   \n",
       "25          2705                        Livres         0.231615   \n",
       "26          2905    Jeux en ligne et Logiciels         0.000884   \n",
       "\n",
       "    prob_class_img  \n",
       "0        76.972038  \n",
       "1         1.634468  \n",
       "2         0.000790  \n",
       "3         0.002508  \n",
       "4         0.010119  \n",
       "5         0.003554  \n",
       "6         0.030007  \n",
       "7         0.026305  \n",
       "8         0.009908  \n",
       "9         0.006016  \n",
       "10        4.202293  \n",
       "11       10.039733  \n",
       "12        0.002177  \n",
       "13        0.052704  \n",
       "14        0.029363  \n",
       "15        0.009569  \n",
       "16        0.001512  \n",
       "17        0.001522  \n",
       "18        2.794771  \n",
       "19        0.106003  \n",
       "20        0.004880  \n",
       "21        0.029293  \n",
       "22        0.301221  \n",
       "23        0.330895  \n",
       "24        0.088429  \n",
       "25        3.304584  \n",
       "26        0.005339  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Données\n",
    "prdtypecode = [10, 40, 50, 60, 1140, 1160, 1180, 1280, 1281,\n",
    "               1300, 1301, 1302, 1320, 1560, 1920, 1940, 2060,\n",
    "               2220, 2280, 2403, 2462, 2522, 2582, 2583,\n",
    "               2585, 2705, 2905]\n",
    "\n",
    "labels = [\"Livres adultes\", \"Jeux Vidéos\", \"Accessoires de Jeux Vidéos\", \"Consoles de jeux\", \"Figurine\", \"Carte à Collectionner\",\n",
    "          \"Masques\", \"Jouets pour Enfants\", \"Jeux de Cartes et de société\", \"Produits télécommandés\",\n",
    "          \"Vêtements pour enfants\", \"Jouets pour Enfants\", \"Produits Bébés et Enfants\",\n",
    "          \"Literies et Meubles\", \"Accessoires Maison\", \"Alimentation\", \"Décoration d'intérieur\", \"Accessoires Animaux\",\n",
    "          \"Journaux et Magazines\", \"Livres et Revues\", \"Jeux\", \"Papeterie\",\n",
    "          \"Mobilier\", \"Piscine\", \"Jardinage\", \"Livres\", \"Jeux en ligne et Logiciels\"]\n",
    "\n",
    "# fonction reshape pour convertir en tableau 1D\n",
    "prob_class_text = (y_pred_text.reshape(-1)) * 100\n",
    "prob_class_img = (y_pred_image.reshape(-1)) * 100\n",
    "\n",
    "# Création du DataFrame\n",
    "data = {'code_produit': prdtypecode, 'labels': labels, 'prob_class_text': prob_class_text, 'prob_class_img': prob_class_img}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Affichage du DataFrame\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_produit       2583\n",
      "labels          Piscine\n",
      "Name: 23, dtype: object\n",
      "code_produit                10\n",
      "labels          Livres adultes\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Indice de la valeur maximale pour prob_class_text\n",
    "idx_max_text = df['prob_class_text'].idxmax()\n",
    "\n",
    "# Indice de la valeur maximale pour prob_class_img\n",
    "idx_max_img = df['prob_class_img'].idxmax()\n",
    "\n",
    "# Suppression des colonnes \n",
    "df_temp = df.drop(columns=['prob_class_text', 'prob_class_img'])\n",
    "\n",
    "# Affichez les valeurs maximales (sans afficher la colonne)\n",
    "print(df_temp.loc[idx_max_text])\n",
    "\n",
    "# Valeur maximale pour prob_class_img (sans afficher la colonne)\n",
    "print(df_temp.loc[idx_max_img])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code_produit            2583\n",
      "labels               Piscine\n",
      "prob_class_text    64.597679\n",
      "prob_class_img      0.330895\n",
      "Name: 23, dtype: object\n",
      "code_produit                   10\n",
      "labels             Livres adultes\n",
      "prob_class_text          0.901587\n",
      "prob_class_img          76.972038\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Indice de la valeur maximale pour prob_class_text\n",
    "idx_max_text = df['prob_class_text'].idxmax()\n",
    "\n",
    "# Indice de la valeur maximale pour prob_class_img\n",
    "idx_max_img = df['prob_class_img'].idxmax()\n",
    "\n",
    "# Valeur maximale pour prob_class_text\n",
    "print(df.loc[idx_max_text])\n",
    "\n",
    "# Valeur maximale pour prob_class_img\n",
    "print(df.loc[idx_max_img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prédictions fusionnées pour l'image (Xception) :\n",
      "Classe prédite : 1\n",
      "Code de produit associé : 40\n",
      "Label associé : Jeux Vidéos\n",
      "\n",
      "Prédictions fusionnées pour le texte (Conv1D) :\n",
      "Texte à prédire :\n",
      "cyclone jamaique traduit anglais jean talva\n",
      "Classe prédite : 0\n",
      "Code de produit associé : 10\n",
      "Label associé : Livres adultes\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/steph/workspace/rakuten_env/modelisation/github_final copy/notebook/prompt_text_im2.ipynb Cell 29\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/steph/workspace/rakuten_env/modelisation/github_final%20copy/notebook/prompt_text_im2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=49'>50</a>\u001b[0m top_classes_indices \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort(\u001b[39m-\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mweighted_proba\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m])[:\u001b[39m2\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/steph/workspace/rakuten_env/modelisation/github_final%20copy/notebook/prompt_text_im2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39m# Pourcentages des deux classes les plus probables\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/steph/workspace/rakuten_env/modelisation/github_final%20copy/notebook/prompt_text_im2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=51'>52</a>\u001b[0m top_class_probabilities \u001b[39m=\u001b[39m df[\u001b[39m'\u001b[39;49m\u001b[39mclass_probabilities\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m][top_classes_indices]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/steph/workspace/rakuten_env/modelisation/github_final%20copy/notebook/prompt_text_im2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Affichage des deux premières classes prédites avec leurs pourcentages\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/steph/workspace/rakuten_env/modelisation/github_final%20copy/notebook/prompt_text_im2.ipynb#X40sdnNjb2RlLXJlbW90ZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mDeux premières classes prédites (Xception) :\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "# Poids pour le modèle Conv1D\n",
    "conv1D_weight = 0.6\n",
    "# Poids pour le modèle Xception\n",
    "xception_weight = 0.4\n",
    "\n",
    "\n",
    "# Calcul des prédictions pondérées pour chaque image\n",
    "df['weighted_proba'] = (df['prob_class_text'] * conv1D_weight + df['prob_class_img'] * xception_weight) / (conv1D_weight + xception_weight)\n",
    "\n",
    "# Sélection des classes prédites pour chaque image\n",
    "df['predicted_classes'] = np.argmax(df[['prob_class_text', 'prob_class_img']].values, axis=1).astype(int)\n",
    "\n",
    "# Calcul des probabilités en pourcentage pour chaque image\n",
    "df['class_probabilities'] = df['weighted_proba'] * 100\n",
    "\n",
    "# Calcul des prédictions fusionnées pour chaque image (calcul de la moyenne pondérée)\n",
    "df['image_predictions'] = df['prob_class_img'] * xception_weight\n",
    "df['text_predictions'] = df['prob_class_text'] * conv1D_weight\n",
    "\n",
    "# Regroupement des prédictions par classe et calcul de la moyenne pondérée\n",
    "image_grouped = df.groupby('predicted_classes')['image_predictions'].mean()\n",
    "text_grouped = df.groupby('predicted_classes')['text_predictions'].mean()\n",
    "\n",
    "# Sélection la classe prédite en fonction de la moyenne pondérée maximale\n",
    "df['image_predicted_class'] = image_grouped.idxmax()\n",
    "df['text_predicted_class'] = text_grouped.idxmax()\n",
    "\n",
    "# Sélection des codes de produit associés aux classes prédites\n",
    "df['image_predicted_code'] = df['code_produit'].loc[df['image_predicted_class']].values\n",
    "df['text_predicted_code'] = df['code_produit'].loc[df['text_predicted_class']].values\n",
    "\n",
    "# Sélection des labels associés aux classes prédites\n",
    "df['image_predicted_label'] = df['labels'].loc[df['image_predicted_class']].values\n",
    "df['text_predicted_label'] = df['labels'].loc[df['text_predicted_class']].values\n",
    "\n",
    "# Affichage des résultats\n",
    "print(\"Prédictions fusionnées pour l'image (Xception) :\")\n",
    "print(\"Classe prédite :\", df['image_predicted_class'].values[0])\n",
    "print(\"Code de produit associé :\", df['image_predicted_code'].values[0])\n",
    "print(\"Label associé :\", df['image_predicted_label'].values[0])\n",
    "\n",
    "print(\"\\nPrédictions fusionnées pour le texte (Conv1D) :\")\n",
    "print(\"Texte à prédire :\")\n",
    "print(df_text['text'].values[0])  # Affichez le texte du premier exemple\n",
    "print(\"Classe prédite :\", df['text_predicted_class'].values[0])\n",
    "print(\"Code de produit associé :\", df['text_predicted_code'].values[0])\n",
    "print(\"Label associé :\", df['text_predicted_label'].values[0])\n",
    "\n",
    "# Récupération des indices des deux classes les plus probables\n",
    "top_classes_indices = np.argsort(-df['weighted_proba'].values[0])[:2]\n",
    "# Pourcentages des deux classes les plus probables\n",
    "top_class_probabilities = df['class_probabilities'].values[0][top_classes_indices]\n",
    "\n",
    "# Affichage des deux premières classes prédites avec leurs pourcentages\n",
    "print(\"\\nDeux premières classes prédites (Xception) :\")\n",
    "for i in range(len(top_classes_indices)):\n",
    "    class_index = top_classes_indices[i]\n",
    "    class_label = df['labels'].iloc[class_index]\n",
    "    class_probability = top_class_probabilities[i]\n",
    "    print(f\"Classe {class_index}: {class_label} - {class_probability:.2f}%\")\n",
    "\n",
    "# Récupération des indices des deux classes les plus probables sur le texte\n",
    "top_text_classes_indices = np.argsort(-df['text_predictions'].values[0])[:2]\n",
    "top_text_class_probabilities = df['class_probabilities'].values[0][top_text_classes_indices]\n",
    "\n",
    "print(\"\\nDeux premières classes prédites (Conv1D) :\")\n",
    "for i in range(len(top_text_classes_indices)):\n",
    "    class_index = top_text_classes_indices[i]\n",
    "    class_label = df['labels'].iloc[class_index]\n",
    "    class_probability = top_text_class_probabilities[i]\n",
    "    print(f\"Classe {class_index}: {class_label} - {class_probability:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rakuten_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
